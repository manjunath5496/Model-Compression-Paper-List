<h2> Model Compression Paper List </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(1).pdf" style="text-decoration:none;">FitNets: Hints for Thin Deep Nets</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(2).pdf" style="text-decoration:none;">Net2Net: Accelerating Learning via Knowledge Transfer</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(3).pdf" style="text-decoration:none;">Binarized Neural Networks: Training Neural Networks withWeights and Activations Constrained to +1 or -1</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(4).pdf" style="text-decoration:none;">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(5).pdf" style="text-decoration:none;">Learning Structured Sparsity in Deep Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(6).pdf" style="text-decoration:none;">Deep Model Compression: Distilling Knowledge from Noisy Teachers</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(7).pdf" style="text-decoration:none;">Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(8).pdf" style="text-decoration:none;"> Coordinating Filters for Faster Deep Neural Networks </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(9).pdf" style="text-decoration:none;">Data-Driven Sparse Structure Selection for Deep Neural Networks</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(10).pdf" style="text-decoration:none;">Like What You Like: Knowledge Distill via Neuron Selectivity Transfer </a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(11).pdf" style="text-decoration:none;">DarkRank: Accelerating Deep Metric Learning via Cross Sample Similarities Transfer</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(12).pdf" style="text-decoration:none;">Binarized Convolutional Neural Networks with Separable Filters for Efficient Hardware Acceleration</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(13).pdf" style="text-decoration:none;">Channel Pruning for Accelerating Very Deep Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(14).pdf" style="text-decoration:none;">Learning Efficient Convolutional Networks through Network Slimming</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(15).pdf" style="text-decoration:none;">Data-Free Knowledge Distillation for Deep Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(16).pdf" style="text-decoration:none;">Moonshine: Distilling with Cheap Convolutions</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(17).pdf" style="text-decoration:none;">NISP: Pruning Networks using Neuron Importance Score Propagation</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(18).pdf" style="text-decoration:none;">MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(19).pdf" style="text-decoration:none;">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(20).pdf" style="text-decoration:none;">Recent Advances in Efficient Computation of Deep Convolutional Neural Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(21).pdf" style="text-decoration:none;">On the Universal Approximability and Complexity Bounds of Quantized ReLU Neural Networks</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(22).pdf" style="text-decoration:none;">Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(23).pdf" style="text-decoration:none;">"Learning-Compression" Algorithms for Neural Net Pruning</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(24).pdf" style="text-decoration:none;">Dark knowledge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(25).pdf" style="text-decoration:none;">Efficient Sparse-Winograd Convolutional Neural Networks</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(26).pdf" style="text-decoration:none;">Speeding up Convolutional Neural Networks with Low Rank Expansions</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(27).pdf" style="text-decoration:none;">SplitNet: Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(28).pdf" style="text-decoration:none;">Model compression via distillation and quantization</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(29).pdf" style="text-decoration:none;">Learning Efficient Object Detection Models with Knowledge Distillation </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(30).pdf" style="text-decoration:none;">Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Model-Compression-Paper-List/blob/master/moc(31).pdf" style="text-decoration:none;">Beyond Filters: Compact Feature Map for Portable Deep Model</a></li> 
    </ul>
  
  
  
